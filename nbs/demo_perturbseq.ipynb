{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# SEDD for Perturbation-Seq Prediction\n",
    "\n",
    "This notebook demonstrates how to use Score-Entropy Discrete Diffusion (SEDD) for perturbation prediction on single-cell RNA-seq data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**Task**: Predict how cells respond to perturbations (gene knockouts, drug treatments, etc.)\n",
    "\n",
    "**Input**: Control cell expression + Perturbation label  \n",
    "**Output**: Predicted perturbed cell expression\n",
    "\n",
    "This implementation is inspired by:\n",
    "- **STATE** (Arc Institute): Virtual cell model for perturbation prediction\n",
    "- **SEDD**: Score-Entropy Discrete Diffusion (ICML 2024 Best Paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-gen-header",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Perturbation-Seq Data\n",
    "\n",
    "We'll create toy perturbation-seq data with:\n",
    "- Multiple perturbations (gene knockouts)\n",
    "- Control cells (unperturbed)\n",
    "- Perturbed cells with perturbation-specific effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-toy-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_synthetic_perturbseq(\n",
    "    num_control_cells: int = 500,\n",
    "    num_perturbed_per_condition: int = 100,\n",
    "    num_genes: int = 200,\n",
    "    num_perturbations: int = 5,\n",
    "    num_bins: int = 100,\n",
    "    sparsity: float = 0.7,\n",
    "    perturbation_effect_size: float = 0.3,\n",
    "    seed: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Create synthetic perturbation-seq data.\n",
    "    \n",
    "    Returns:\n",
    "        expression: Discretized expression matrix [num_cells, num_genes]\n",
    "        pert_labels: Perturbation labels (strings)\n",
    "        gene_names: Gene names\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # Gene names\n",
    "    gene_names = [f'Gene_{i}' for i in range(num_genes)]\n",
    "    pert_names = ['control'] + [f'KO_Gene_{i}' for i in range(num_perturbations)]\n",
    "    \n",
    "    # Generate baseline expression (control cells)\n",
    "    baseline_mean = rng.uniform(10, 50, num_genes)\n",
    "    \n",
    "    # Control cells\n",
    "    control_expression = rng.poisson(baseline_mean, (num_control_cells, num_genes)).astype(float)\n",
    "    control_labels = ['control'] * num_control_cells\n",
    "    \n",
    "    all_expression = [control_expression]\n",
    "    all_labels = control_labels\n",
    "    \n",
    "    # Generate perturbed cells\n",
    "    for pert_idx in range(num_perturbations):\n",
    "        # Each perturbation affects a subset of genes\n",
    "        affected_genes = rng.choice(num_genes, size=num_genes // 10, replace=False)\n",
    "        \n",
    "        # Create perturbation effect\n",
    "        pert_mean = baseline_mean.copy()\n",
    "        for gene_idx in affected_genes:\n",
    "            # Some genes go up, some go down\n",
    "            direction = rng.choice([-1, 1])\n",
    "            pert_mean[gene_idx] *= (1 + direction * perturbation_effect_size)\n",
    "        \n",
    "        # Generate perturbed cells\n",
    "        pert_expression = rng.poisson(pert_mean, (num_perturbed_per_condition, num_genes)).astype(float)\n",
    "        pert_label = pert_names[pert_idx + 1]\n",
    "        \n",
    "        all_expression.append(pert_expression)\n",
    "        all_labels.extend([pert_label] * num_perturbed_per_condition)\n",
    "    \n",
    "    # Combine all cells\n",
    "    expression = np.vstack(all_expression)\n",
    "    \n",
    "    # Apply sparsity\n",
    "    mask = rng.rand(*expression.shape) < sparsity\n",
    "    expression[mask] = 0\n",
    "    \n",
    "    # Discretize expression into bins\n",
    "    non_zero = expression[expression > 0]\n",
    "    if len(non_zero) > 0:\n",
    "        # Log-transform and create bins\n",
    "        log_expr = np.log1p(expression)\n",
    "        max_val = log_expr.max()\n",
    "        \n",
    "        # Create bins\n",
    "        discretized = np.zeros_like(expression, dtype=np.int64)\n",
    "        discretized[expression > 0] = np.clip(\n",
    "            (log_expr[expression > 0] / max_val * (num_bins - 1)).astype(int) + 1,\n",
    "            1, num_bins\n",
    "        )\n",
    "    else:\n",
    "        discretized = expression.astype(np.int64)\n",
    "    \n",
    "    return discretized, all_labels, gene_names, pert_names\n",
    "\n",
    "\n",
    "# Generate data\n",
    "expression, pert_labels, gene_names, pert_names = create_synthetic_perturbseq(\n",
    "    num_control_cells=500,\n",
    "    num_perturbed_per_condition=100,\n",
    "    num_genes=200,\n",
    "    num_perturbations=5,\n",
    "    num_bins=100,\n",
    "    sparsity=0.7,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f'Expression shape: {expression.shape}')\n",
    "print(f'Perturbation labels: {len(set(pert_labels))} unique')\n",
    "print(f'Perturbations: {pert_names}')\n",
    "print(f'Sparsity: {(expression == 0).mean():.2%}')\n",
    "\n",
    "# Count cells per perturbation\n",
    "unique, counts = np.unique(pert_labels, return_counts=True)\n",
    "for name, count in zip(unique, counts):\n",
    "    print(f'  {name}: {count} cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize expression distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Bin distribution\n",
    "axes[0].hist(expression[expression > 0].flatten(), bins=50, alpha=0.7)\n",
    "axes[0].set_xlabel('Expression Bin')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Discretized Expression Distribution (non-zero)')\n",
    "\n",
    "# Per-perturbation statistics\n",
    "pert_means = []\n",
    "for pert in pert_names:\n",
    "    mask = np.array(pert_labels) == pert\n",
    "    pert_means.append(expression[mask].mean())\n",
    "\n",
    "axes[1].bar(range(len(pert_names)), pert_means, alpha=0.7)\n",
    "axes[1].set_xticks(range(len(pert_names)))\n",
    "axes[1].set_xticklabels(pert_names, rotation=45, ha='right')\n",
    "axes[1].set_xlabel('Perturbation')\n",
    "axes[1].set_ylabel('Mean Expression Bin')\n",
    "axes[1].set_title('Mean Expression by Perturbation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dataset-header",
   "metadata": {},
   "source": [
    "## 2. Create PerturbSeqDataset\n",
    "\n",
    "The `PerturbSeqDataset` handles control-perturbed cell pairs and perturbation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedd.data import PerturbSeqDataset, train_val_split\n",
    "\n",
    "# Create dataset\n",
    "NUM_BINS = 100\n",
    "\n",
    "dataset = PerturbSeqDataset(\n",
    "    expression=expression,\n",
    "    pert_labels=pert_labels,\n",
    "    gene_names=gene_names,\n",
    "    num_bins=NUM_BINS,\n",
    "    control_pert_name='control'\n",
    ")\n",
    "\n",
    "print(f'\\nDataset info:')\n",
    "print(f'  Perturbed cells: {len(dataset)}')\n",
    "print(f'  Control cells: {len(dataset.control_expression)}')\n",
    "print(f'  Number of genes: {dataset.num_genes}')\n",
    "print(f'  Number of perturbations: {dataset.num_perturbations}')\n",
    "print(f'  Number of bins: {dataset.num_bins}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inspect-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a sample from the dataset\n",
    "control, pert_label, perturbed = dataset[0]\n",
    "\n",
    "print(f'Sample from dataset:')\n",
    "print(f'  Control shape: {control.shape}')\n",
    "print(f'  Perturbation label: {pert_label.item()}')\n",
    "print(f'  Perturbed shape: {perturbed.shape}')\n",
    "\n",
    "# Visualize the triplet\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 9))\n",
    "\n",
    "gene_indices = np.arange(dataset.num_genes)\n",
    "\n",
    "axes[0].bar(gene_indices, control.numpy(), alpha=0.7, width=1.0, color='blue')\n",
    "axes[0].set_ylabel('Expression Bin')\n",
    "axes[0].set_title('Control Cell Expression')\n",
    "\n",
    "axes[1].bar(gene_indices, perturbed.numpy(), alpha=0.7, width=1.0, color='red')\n",
    "axes[1].set_ylabel('Expression Bin')\n",
    "axes[1].set_title(f'Perturbed Cell Expression (Label: {pert_label.item()})')\n",
    "\n",
    "# Difference\n",
    "diff = perturbed.numpy() - control.numpy()\n",
    "colors = ['green' if d > 0 else 'orange' if d < 0 else 'gray' for d in diff]\n",
    "axes[2].bar(gene_indices, diff, alpha=0.7, width=1.0, color=colors)\n",
    "axes[2].axhline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "axes[2].set_xlabel('Gene Index')\n",
    "axes[2].set_ylabel('Expression Difference')\n",
    "axes[2].set_title('Perturbation Effect (Perturbed - Control)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-dataloaders",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/val\n",
    "train_dataset, val_dataset = train_val_split(dataset, val_fraction=0.15, seed=42)\n",
    "print(f'Train size: {len(train_dataset)}, Val size: {len(val_dataset)}')\n",
    "\n",
    "# Create dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f'Number of training batches: {len(train_loader)}')\n",
    "print(f'Number of validation batches: {len(val_loader)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## 3. Create Perturbation Prediction Model\n",
    "\n",
    "We use `SEDDPerturbationTransformer` which conditions on perturbation labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedd.model import SEDDPerturbationTransformerSmall\n",
    "from sedd.graph import AbsorbingGraph\n",
    "from sedd.noise import LogLinearNoise\n",
    "\n",
    "# Model parameters\n",
    "NUM_GENES = dataset.num_genes\n",
    "NUM_PERTURBATIONS = dataset.num_perturbations\n",
    "VOCAB_SIZE = NUM_BINS + 1  # +1 for mask token\n",
    "\n",
    "# Create model with perturbation conditioning\n",
    "model = SEDDPerturbationTransformerSmall(\n",
    "    num_genes=NUM_GENES,\n",
    "    num_bins=NUM_BINS,\n",
    "    num_perturbations=NUM_PERTURBATIONS,\n",
    "    hidden_dim=128,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Diffusion components\n",
    "graph = AbsorbingGraph(num_states=VOCAB_SIZE)\n",
    "noise = LogLinearNoise(eps=1e-3)\n",
    "\n",
    "# Count parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Model parameters: {num_params:,}')\n",
    "print(f'\\nModel architecture:')\n",
    "print(f'  Genes: {NUM_GENES}')\n",
    "print(f'  Bins: {NUM_BINS}')\n",
    "print(f'  Perturbations: {NUM_PERTURBATIONS}')\n",
    "print(f'  Hidden dim: 128')\n",
    "print(f'  Layers: 4')\n",
    "print(f'  Heads: 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train-header",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "Training objective: Predict perturbed cell from masked perturbed cell + perturbation label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedd.trainer import PerturbationTrainer\n",
    "\n",
    "# Create trainer\n",
    "trainer = PerturbationTrainer(\n",
    "    model=model,\n",
    "    graph=graph,\n",
    "    noise=noise,\n",
    "    device=device,\n",
    "    gradient_clip=1.0\n",
    ")\n",
    "\n",
    "print('Trainer created successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for a few epochs (use more epochs for better results)\n",
    "NUM_EPOCHS = 30\n",
    "MASK_RATIO = 0.15  # Fraction of genes to mask during training\n",
    "\n",
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    mask_ratio=MASK_RATIO,\n",
    "    log_interval=5,\n",
    "    val_interval=1\n",
    ")\n",
    "\n",
    "print('\\nTraining complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "ax.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "ax.plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "ax.set_xlabel('Epoch', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Training Progress', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Final train loss: {history[\"train_loss\"][-1]:.4f}')\n",
    "print(f'Final val loss: {history[\"val_loss\"][-1]:.4f}')\n",
    "print(f'Best val loss: {trainer.best_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference-header",
   "metadata": {},
   "source": [
    "## 5. Inference: Predict Perturbed Cells\n",
    "\n",
    "Now we test the model's ability to predict how cells respond to perturbations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedd.sampling import EulerSampler\n",
    "\n",
    "# Set model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# Get a test batch\n",
    "test_control, test_pert_labels, test_perturbed = next(iter(val_loader))\n",
    "test_control = test_control.to(device)\n",
    "test_pert_labels = test_pert_labels.to(device)\n",
    "test_perturbed = test_perturbed.to(device)\n",
    "\n",
    "print(f'Test batch:')\n",
    "print(f'  Controls: {test_control.shape}')\n",
    "print(f'  Pert labels: {test_pert_labels.shape}')\n",
    "print(f'  True perturbed: {test_perturbed.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference-predict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict perturbed cells using sampling\n",
    "# We start from all-masked and condition on perturbation labels\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Create sampler\n",
    "    sampler = EulerSampler(\n",
    "        model=model,\n",
    "        graph=graph,\n",
    "        noise=noise,\n",
    "        num_steps=50,\n",
    "        device=device,\n",
    "        temperature=1.0\n",
    "    )\n",
    "    \n",
    "    # Start from all masked\n",
    "    batch_size = test_control.shape[0]\n",
    "    x_init = torch.full((batch_size, NUM_GENES), graph.mask_index, device=device)\n",
    "    \n",
    "    # Sample with perturbation conditioning\n",
    "    # Note: Current sampler doesn't take pert_labels, so we'll use a simpler approach\n",
    "    # For full implementation, we'd need to modify the sampler\n",
    "    \n",
    "    # Simple prediction: forward pass with low noise\n",
    "    sigma = torch.ones(batch_size, device=device) * 0.01\n",
    "    logits = model(x_init, sigma, test_pert_labels)\n",
    "    predicted = logits.argmax(dim=-1)\n",
    "\n",
    "print(f'Predicted perturbed cells: {predicted.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate-predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "with torch.no_grad():\n",
    "    # Exact match accuracy\n",
    "    accuracy = (predicted == test_perturbed).float().mean().item()\n",
    "    print(f'Exact match accuracy: {accuracy:.2%}')\n",
    "    \n",
    "    # Mean absolute error\n",
    "    mae = (predicted - test_perturbed).abs().float().mean().item()\n",
    "    print(f'Mean Absolute Error: {mae:.2f} bins')\n",
    "    \n",
    "    # Within-k accuracy\n",
    "    for k in [1, 3, 5, 10]:\n",
    "        within_k = ((predicted - test_perturbed).abs() <= k).float().mean().item()\n",
    "        print(f'Within {k} bins: {within_k:.2%}')\n",
    "    \n",
    "    # Per-gene correlation\n",
    "    gene_corrs = []\n",
    "    for gene_idx in range(NUM_GENES):\n",
    "        true_vals = test_perturbed[:, gene_idx].cpu().numpy()\n",
    "        pred_vals = predicted[:, gene_idx].cpu().numpy()\n",
    "        if true_vals.std() > 0 and pred_vals.std() > 0:\n",
    "            corr = np.corrcoef(true_vals, pred_vals)[0, 1]\n",
    "            gene_corrs.append(corr)\n",
    "    \n",
    "    avg_corr = np.mean(gene_corrs) if gene_corrs else 0\n",
    "    print(f'\\nAverage per-gene correlation: {avg_corr:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs ground truth\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scatter plot\n",
    "true_flat = test_perturbed.cpu().numpy().flatten()\n",
    "pred_flat = predicted.cpu().numpy().flatten()\n",
    "\n",
    "axes[0].scatter(true_flat, pred_flat, alpha=0.2, s=5)\n",
    "axes[0].plot([0, NUM_BINS], [0, NUM_BINS], 'r--', linewidth=2, label='Perfect prediction')\n",
    "axes[0].set_xlabel('True Expression Bin', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Expression Bin', fontsize=12)\n",
    "axes[0].set_title('Perturbation Prediction: Predicted vs True', fontsize=13)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Error distribution\n",
    "errors = (pred_flat - true_flat)\n",
    "axes[1].hist(errors, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(0, color='r', linestyle='--', linewidth=2, label='Zero error')\n",
    "axes[1].set_xlabel('Prediction Error (bins)', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].set_title('Prediction Error Distribution', fontsize=13)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "examples-header",
   "metadata": {},
   "source": [
    "## 6. Example Predictions\n",
    "\n",
    "Let's look at individual cell predictions in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-cell-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize individual predictions\n",
    "cell_idx = 0\n",
    "\n",
    "control_cell = test_control[cell_idx].cpu().numpy()\n",
    "true_perturbed = test_perturbed[cell_idx].cpu().numpy()\n",
    "pred_perturbed = predicted[cell_idx].cpu().numpy()\n",
    "pert_label = test_pert_labels[cell_idx].item()\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "\n",
    "gene_indices = np.arange(NUM_GENES)\n",
    "\n",
    "# Control\n",
    "axes[0].bar(gene_indices, control_cell, alpha=0.7, width=1.0, color='blue')\n",
    "axes[0].set_ylabel('Expression Bin', fontsize=11)\n",
    "axes[0].set_title(f'Control Cell Expression', fontsize=12)\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# True perturbed\n",
    "axes[1].bar(gene_indices, true_perturbed, alpha=0.7, width=1.0, color='red')\n",
    "axes[1].set_ylabel('Expression Bin', fontsize=11)\n",
    "axes[1].set_title(f'True Perturbed Cell (Label: {pert_label})', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Predicted perturbed\n",
    "axes[2].bar(gene_indices, pred_perturbed, alpha=0.7, width=1.0, color='green')\n",
    "axes[2].set_ylabel('Expression Bin', fontsize=11)\n",
    "axes[2].set_title(f'Predicted Perturbed Cell', fontsize=12)\n",
    "axes[2].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Prediction error\n",
    "error = pred_perturbed - true_perturbed\n",
    "colors = ['green' if abs(e) <= 5 else 'orange' if abs(e) <= 10 else 'red' for e in error]\n",
    "axes[3].bar(gene_indices, error, alpha=0.7, width=1.0, color=colors)\n",
    "axes[3].axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "axes[3].set_xlabel('Gene Index', fontsize=11)\n",
    "axes[3].set_ylabel('Prediction Error', fontsize=11)\n",
    "axes[3].set_title('Prediction Error (Green: ≤5 bins, Orange: ≤10 bins, Red: >10 bins)', fontsize=12)\n",
    "axes[3].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics for this cell\n",
    "cell_acc = (true_perturbed == pred_perturbed).mean()\n",
    "cell_mae = np.abs(error).mean()\n",
    "print(f'\\nCell {cell_idx} metrics:')\n",
    "print(f'  Accuracy: {cell_acc:.2%}')\n",
    "print(f'  MAE: {cell_mae:.2f} bins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions for multiple cells\n",
    "num_examples = 4\n",
    "fig, axes = plt.subplots(num_examples, 3, figsize=(15, 3 * num_examples))\n",
    "\n",
    "for i in range(num_examples):\n",
    "    control_cell = test_control[i].cpu().numpy()\n",
    "    true_cell = test_perturbed[i].cpu().numpy()\n",
    "    pred_cell = predicted[i].cpu().numpy()\n",
    "    pert_label = test_pert_labels[i].item()\n",
    "    \n",
    "    # Control\n",
    "    axes[i, 0].bar(range(NUM_GENES), control_cell, alpha=0.7, width=1.0, color='blue')\n",
    "    axes[i, 0].set_ylabel('Bin', fontsize=10)\n",
    "    axes[i, 0].set_title(f'Cell {i}: Control', fontsize=11)\n",
    "    \n",
    "    # True perturbed\n",
    "    axes[i, 1].bar(range(NUM_GENES), true_cell, alpha=0.7, width=1.0, color='red')\n",
    "    axes[i, 1].set_title(f'True Perturbed (Label {pert_label})', fontsize=11)\n",
    "    \n",
    "    # Predicted\n",
    "    axes[i, 2].bar(range(NUM_GENES), pred_cell, alpha=0.7, width=1.0, color='green')\n",
    "    axes[i, 2].set_title(f'Predicted Perturbed', fontsize=11)\n",
    "    \n",
    "    if i == num_examples - 1:\n",
    "        axes[i, 0].set_xlabel('Gene', fontsize=10)\n",
    "        axes[i, 1].set_xlabel('Gene', fontsize=10)\n",
    "        axes[i, 2].set_xlabel('Gene', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perturbation-analysis-header",
   "metadata": {},
   "source": [
    "## 7. Analyze Perturbation-Specific Performance\n",
    "\n",
    "Let's see how well the model predicts different perturbations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "per-perturbation-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics per perturbation\n",
    "pert_metrics = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for pert_idx in range(NUM_PERTURBATIONS):\n",
    "        mask = (test_pert_labels == pert_idx)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        true_vals = test_perturbed[mask]\n",
    "        pred_vals = predicted[mask]\n",
    "        \n",
    "        acc = (true_vals == pred_vals).float().mean().item()\n",
    "        mae = (true_vals - pred_vals).abs().float().mean().item()\n",
    "        within_5 = ((true_vals - pred_vals).abs() <= 5).float().mean().item()\n",
    "        \n",
    "        pert_metrics[pert_idx] = {\n",
    "            'accuracy': acc,\n",
    "            'mae': mae,\n",
    "            'within_5': within_5,\n",
    "            'num_cells': mask.sum().item()\n",
    "        }\n",
    "\n",
    "# Display metrics\n",
    "print('Per-perturbation metrics:\\n')\n",
    "for pert_idx, metrics in pert_metrics.items():\n",
    "    print(f'Perturbation {pert_idx}:')\n",
    "    print(f'  Cells: {metrics[\"num_cells\"]}')\n",
    "    print(f'  Accuracy: {metrics[\"accuracy\"]:.2%}')\n",
    "    print(f'  MAE: {metrics[\"mae\"]:.2f}')\n",
    "    print(f'  Within 5 bins: {metrics[\"within_5\"]:.2%}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-per-perturbation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize per-perturbation performance\n",
    "if pert_metrics:\n",
    "    pert_indices = list(pert_metrics.keys())\n",
    "    accuracies = [pert_metrics[i]['accuracy'] for i in pert_indices]\n",
    "    maes = [pert_metrics[i]['mae'] for i in pert_indices]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0].bar(pert_indices, accuracies, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    axes[0].set_xlabel('Perturbation Index', fontsize=12)\n",
    "    axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axes[0].set_title('Prediction Accuracy by Perturbation', fontsize=13)\n",
    "    axes[0].set_ylim([0, 1])\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # MAE\n",
    "    axes[1].bar(pert_indices, maes, alpha=0.7, color='coral', edgecolor='black')\n",
    "    axes[1].set_xlabel('Perturbation Index', fontsize=12)\n",
    "    axes[1].set_ylabel('MAE (bins)', fontsize=12)\n",
    "    axes[1].set_title('Mean Absolute Error by Perturbation', fontsize=13)\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## 8. Save and Load Model\n",
    "\n",
    "Save the trained model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create checkpoints directory\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "trainer.save_checkpoint('checkpoints/demo_perturbseq_model.pt')\n",
    "print('Model saved to checkpoints/demo_perturbseq_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model (demonstration)\n",
    "new_model = SEDDPerturbationTransformerSmall(\n",
    "    num_genes=NUM_GENES,\n",
    "    num_bins=NUM_BINS,\n",
    "    num_perturbations=NUM_PERTURBATIONS,\n",
    "    hidden_dim=128,\n",
    "    num_layers=4,\n",
    "    num_heads=4,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "new_trainer = PerturbationTrainer(\n",
    "    model=new_model,\n",
    "    graph=graph,\n",
    "    noise=noise,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "new_trainer.load_checkpoint('checkpoints/demo_perturbseq_model.pt')\n",
    "print(f'Model loaded! Trained for {new_trainer.epoch + 1} epochs.')\n",
    "print(f'Best validation loss: {new_trainer.best_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated:\n",
    "\n",
    "1. **Data Generation**: Created synthetic perturbation-seq data with multiple perturbations\n",
    "2. **Dataset**: Used `PerturbSeqDataset` to handle control-perturbed cell pairs\n",
    "3. **Model**: Built `SEDDPerturbationTransformer` with perturbation conditioning\n",
    "4. **Training**: Trained the model using discrete diffusion with masking\n",
    "5. **Inference**: Predicted perturbed cell states from control cells + perturbation labels\n",
    "6. **Evaluation**: Analyzed prediction accuracy and perturbation-specific performance\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Train on real perturbation-seq datasets (e.g., from [cell-load](https://github.com/ArcInstitute/cell-load))\n",
    "- Use larger models (Medium/Large) for better performance\n",
    "- Implement advanced sampling strategies\n",
    "- Compare with other perturbation prediction methods\n",
    "- Analyze learned perturbation embeddings\n",
    "\n",
    "### References\n",
    "\n",
    "- **STATE**: [Paper](https://www.biorxiv.org/content/10.1101/2025.06.26.661135v1) | [Code](https://github.com/ArcInstitute/state)\n",
    "- **SEDD**: [Code](https://github.com/louaaron/Score-Entropy-Discrete-Diffusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
