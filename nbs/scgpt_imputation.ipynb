{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# scGPT Model Imputation Inference\n\nThis notebook demonstrates how to:\n1. Load a pre-trained scGPT model\n2. Perform gene expression imputation\n3. Evaluate and visualize results\n\n## Model Files Location\n\nThe model is loaded from `models/scGPT/` directory. Note that `models/` is typically\na symlink to your GPU storage (e.g., `/scratch/user/st2/models/`).\n\nPlace your pre-trained scGPT model files in that directory with the following structure:\n```\nmodels/scGPT/\n├── args.json              # Model configuration (required)\n├── best_model.pt          # Model weights (required, or best_model.ckpt)\n├── vocab.json             # Gene vocabulary (required)\n├── var_dims.pkl           # Variable dimensions (optional)\n└── pert_one-hot-map.pt    # Perturbation mapping (optional)\n```"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_DIR = \"models/scGPT\"\n",
    "DATA_PATH = \"/home/b5cc/sanjukta.b5cc/aracneseq/datasets/k562_5k.h5ad\"  # Update with your data path\n",
    "MASK_RATIO = 0.2\n",
    "VAL_FRACTION = 0.1\n",
    "BATCH_SIZE = 16\n",
    "NUM_BATCHES = None  # None = evaluate all batches\n",
    "NUM_CELLS_VISUALIZE = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load scGPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = Path(MODEL_DIR)\n",
    "\n",
    "# Load model configuration\n",
    "with open(model_dir / \"args.json\", \"r\") as f:\n",
    "    model_args = json.load(f)\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "for key, value in model_args.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "with open(model_dir / \"vocab.json\", \"r\") as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "print(f\"Vocabulary size: {len(vocab)} genes\")\n",
    "print(f\"First 5 genes: {list(vocab.keys())[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variable dimensions if available\n",
    "var_dims_path = model_dir / \"var_dims.pkl\"\n",
    "if var_dims_path.exists():\n",
    "    with open(var_dims_path, \"rb\") as f:\n",
    "        var_dims = pickle.load(f)\n",
    "    print(f\"Loaded variable dimensions: {var_dims}\")\n",
    "else:\n",
    "    var_dims = None\n",
    "    print(\"No var_dims.pkl found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scGPT\n",
    "try:\n",
    "    from scgpt.model import TransformerModel\n",
    "    from scgpt.tokenizer import tokenize_and_pad_batch\n",
    "    from scgpt.preprocess import Preprocessor\n",
    "    print(\"scGPT imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"ERROR: scGPT not installed. Install with: pip install scgpt\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = TransformerModel(\n",
    "    ntoken=model_args.get(\"ntoken\", len(vocab) + 1),\n",
    "    d_model=model_args.get(\"d_model\", 512),\n",
    "    nhead=model_args.get(\"nhead\", 8),\n",
    "    d_hid=model_args.get(\"d_hid\", 512),\n",
    "    nlayers=model_args.get(\"nlayers\", 12),\n",
    "    dropout=model_args.get(\"dropout\", 0.2),\n",
    "    pad_token=model_args.get(\"pad_token\", \"<pad>\"),\n",
    "    pad_value=model_args.get(\"pad_value\", 0),\n",
    "    do_mvc=model_args.get(\"do_mvc\", True),\n",
    "    do_dab=model_args.get(\"do_dab\", False),\n",
    "    use_batch_labels=model_args.get(\"use_batch_labels\", False),\n",
    "    domain_spec_batchnorm=model_args.get(\"domain_spec_batchnorm\", False),\n",
    "    n_input_bins=model_args.get(\"n_input_bins\", 51),\n",
    ")\n",
    "\n",
    "print(f\"Created model with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model weights\n",
    "checkpoint_path = model_dir / \"best_model.pt\"\n",
    "if not checkpoint_path.exists():\n",
    "    checkpoint_path = model_dir / \"best_model.ckpt\"\n",
    "\n",
    "print(f\"Loading weights from: {checkpoint_path}\")\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(\"Loaded from checkpoint dict\")\n",
    "else:\n",
    "    model.load_state_dict(checkpoint)\n",
    "    print(\"Loaded state dict directly\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "print(f\"Loading data from: {DATA_PATH}\")\n",
    "adata = sc.read_h5ad(DATA_PATH)\n",
    "print(f\"Loaded {len(adata)} cells with {adata.n_vars} genes\")\n",
    "print(f\"Data shape: {adata.X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor\n",
    "if hasattr(adata.X, 'toarray'):\n",
    "    expression = adata.X.toarray()\n",
    "else:\n",
    "    expression = adata.X\n",
    "\n",
    "dataset = torch.tensor(expression).long()\n",
    "\n",
    "# Dataset statistics\n",
    "NUM_BINS = int(dataset.max().item())\n",
    "NUM_GENES = dataset.shape[1]\n",
    "VOCAB_SIZE = NUM_BINS + 1\n",
    "\n",
    "print(f\"Number of genes: {NUM_GENES}\")\n",
    "print(f\"Number of bins: {NUM_BINS}\")\n",
    "print(f\"Vocabulary size: {VOCAB_SIZE}\")\n",
    "print(f\"Min value: {dataset.min().item()}\")\n",
    "print(f\"Max value: {dataset.max().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "indices = np.arange(len(dataset))\n",
    "train_idx, val_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=VAL_FRACTION,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Use validation split for testing\n",
    "eval_dataset = dataset[val_idx]\n",
    "print(f\"Validation set: {len(eval_dataset)} cells\")\n",
    "\n",
    "# Create data loader\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(eval_dataset),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,  # Use 0 for notebook\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(f\"Number of batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Imputation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_with_scgpt(model, batch, mask, device):\n",
    "    \"\"\"\n",
    "    Perform imputation using scGPT model.\n",
    "    \n",
    "    Args:\n",
    "        model: scGPT model\n",
    "        batch: Input data tensor [batch_size, num_genes]\n",
    "        mask: Boolean mask indicating positions to impute [batch_size, num_genes]\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        Imputed data tensor [batch_size, num_genes]\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Create masked input\n",
    "        masked_batch = batch.clone()\n",
    "        masked_batch[mask] = 0  # Mask token is typically 0\n",
    "        \n",
    "        # Forward pass through model\n",
    "        output = model(\n",
    "            masked_batch.to(device),\n",
    "            src_key_padding_mask=None,\n",
    "            batch_labels=None\n",
    "        )\n",
    "        \n",
    "        # Get predictions\n",
    "        if isinstance(output, dict):\n",
    "            predictions = output.get('mlm_output', output.get('pred', output))\n",
    "        else:\n",
    "            predictions = output\n",
    "        \n",
    "        # Take argmax to get discrete predictions\n",
    "        if predictions.dim() == 3:  # [batch, seq, vocab]\n",
    "            predictions = predictions.argmax(dim=-1)\n",
    "        \n",
    "        # Combine original and imputed values\n",
    "        result = batch.clone()\n",
    "        result[mask] = predictions[mask]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Running imputation with mask_ratio={MASK_RATIO}\")\n",
    "\n",
    "all_original_masked = []\n",
    "all_predicted_masked = []\n",
    "sample_cells_original = []\n",
    "sample_cells_imputed = []\n",
    "sample_cells_masks = []\n",
    "\n",
    "num_batches = NUM_BATCHES or len(test_loader)\n",
    "\n",
    "for i, (batch,) in enumerate(tqdm(test_loader, total=num_batches, desc=\"Imputing\")):\n",
    "    if i >= num_batches:\n",
    "        break\n",
    "    \n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    # Create random mask\n",
    "    mask = torch.rand_like(batch.float()) < MASK_RATIO\n",
    "    \n",
    "    # Impute masked positions\n",
    "    imputed = impute_with_scgpt(model, batch, mask, device)\n",
    "    \n",
    "    # Collect results\n",
    "    original_masked = batch[mask]\n",
    "    predicted_masked = imputed[mask]\n",
    "    \n",
    "    all_original_masked.append(original_masked.cpu())\n",
    "    all_predicted_masked.append(predicted_masked.cpu())\n",
    "    \n",
    "    # Save some cells for visualization\n",
    "    if len(sample_cells_original) < NUM_CELLS_VISUALIZE:\n",
    "        for j in range(min(NUM_CELLS_VISUALIZE - len(sample_cells_original), batch.size(0))):\n",
    "            sample_cells_original.append(batch[j].cpu())\n",
    "            sample_cells_imputed.append(imputed[j].cpu())\n",
    "            sample_cells_masks.append(mask[j].cpu())\n",
    "\n",
    "# Concatenate all results\n",
    "all_original_masked = torch.cat(all_original_masked)\n",
    "all_predicted_masked = torch.cat(all_predicted_masked)\n",
    "\n",
    "print(f\"Total masked positions evaluated: {len(all_original_masked):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"scGPT Imputation Metrics\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "accuracy = (all_original_masked == all_predicted_masked).float().mean().item()\n",
    "print(f\"Exact match accuracy: {accuracy:.2%}\")\n",
    "\n",
    "mae = (all_original_masked - all_predicted_masked).abs().float().mean().item()\n",
    "print(f\"Mean Absolute Error (bins): {mae:.2f}\")\n",
    "\n",
    "within_k_metrics = {}\n",
    "for k in [1, 3, 5, 10]:\n",
    "    within_k = ((all_original_masked - all_predicted_masked).abs() <= k).float().mean().item()\n",
    "    within_k_metrics[k] = within_k\n",
    "    print(f\"Within {k} bins: {within_k:.2%}\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot and error distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].scatter(\n",
    "    all_original_masked.numpy(),\n",
    "    all_predicted_masked.numpy(),\n",
    "    alpha=0.3,\n",
    "    s=10\n",
    ")\n",
    "axes[0].plot([0, NUM_BINS], [0, NUM_BINS], 'r--', label='Perfect prediction')\n",
    "axes[0].set_xlabel('True Bin')\n",
    "axes[0].set_ylabel('Predicted Bin')\n",
    "axes[0].set_title('scGPT Imputation: Predicted vs True')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "errors = (all_predicted_masked - all_original_masked).numpy()\n",
    "axes[1].hist(errors, bins=50, alpha=0.7)\n",
    "axes[1].axvline(0, color='r', linestyle='--', label='Zero error')\n",
    "axes[1].set_xlabel('Prediction Error (bins)')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Prediction Error Distribution')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual cell visualizations\n",
    "for cell_idx in range(len(sample_cells_original)):\n",
    "    original_cell = sample_cells_original[cell_idx].numpy()\n",
    "    imputed_cell = sample_cells_imputed[cell_idx].numpy()\n",
    "    cell_mask = sample_cells_masks[cell_idx].numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 6))\n",
    "    \n",
    "    gene_indices = np.arange(len(original_cell))\n",
    "    \n",
    "    # Original\n",
    "    axes[0].bar(gene_indices, original_cell, alpha=0.7, label='Original', width=1.0)\n",
    "    axes[0].scatter(gene_indices[cell_mask], original_cell[cell_mask],\n",
    "                   c='red', s=20, zorder=5, label='Masked positions')\n",
    "    axes[0].set_xlabel('Gene Index')\n",
    "    axes[0].set_ylabel('Expression Bin')\n",
    "    axes[0].set_title(f'Cell {cell_idx}: Original Expression (masked positions highlighted)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Imputed\n",
    "    axes[1].bar(gene_indices, imputed_cell, alpha=0.7, label='Imputed', width=1.0, color='green')\n",
    "    axes[1].scatter(gene_indices[cell_mask], imputed_cell[cell_mask],\n",
    "                   c='darkgreen', s=20, zorder=5, label='Imputed positions')\n",
    "    axes[1].set_xlabel('Gene Index')\n",
    "    axes[1].set_ylabel('Expression Bin')\n",
    "    axes[1].set_title(f'Cell {cell_idx}: scGPT Imputed Expression')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Cell-specific metrics\n",
    "    cell_acc = (original_cell[cell_mask] == imputed_cell[cell_mask]).mean()\n",
    "    cell_mae = np.abs(original_cell[cell_mask] - imputed_cell[cell_mask]).mean()\n",
    "    print(f\"Cell {cell_idx} - Accuracy: {cell_acc:.2%}, MAE: {cell_mae:.2f} bins\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics to model directory\n",
    "output_dir = model_dir / \"imputation_results\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "metrics = {\n",
    "    \"model\": \"scGPT\",\n",
    "    \"accuracy\": accuracy,\n",
    "    \"mae_bins\": mae,\n",
    "    \"within_k\": within_k_metrics,\n",
    "    \"mask_ratio\": MASK_RATIO,\n",
    "    \"num_masked_positions\": len(all_original_masked),\n",
    "    \"model_dir\": str(model_dir)\n",
    "}\n",
    "\n",
    "with open(output_dir / \"metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {output_dir}\")\n",
    "print(f\"Metrics saved to: {output_dir / 'metrics.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. Loading a pre-trained scGPT model from checkpoint files\n",
    "2. Running gene expression imputation on masked data\n",
    "3. Evaluating imputation quality with multiple metrics\n",
    "4. Visualizing results at both aggregate and single-cell levels\n",
    "\n",
    "The results are saved to the model directory for comparison with other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}